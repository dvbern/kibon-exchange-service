# Configuration file
# key = value
quarkus.oidc.auth-server-url=http://localhost:8180/auth/realms/kibon
quarkus.oidc.client-id=kibon-exchange-service
quarkus.oidc.credentials.secret=4cf4f780-3856-46ee-850d-f07789675a33

quarkus.datasource.url=jdbc:postgresql://localhost:15432/kibon-exchange
quarkus.datasource.driver=org.postgresql.Driver
quarkus.datasource.username=kibonExchange
quarkus.datasource.password=kibonExchange

# in dev mode, apply entity changes directly. We don't care about existing data
# unfortunately, this does not reapply FlyWay migrations
%dev.quarkus.hibernate-orm.database.generation=drop-and-create
%dev.quarkus.hibernate-orm.sql-load-script=import-dev.sql

# use this to incrementally work in your app while keeping data
# useful for rapid dev-check cycles with Quarkus dev mode
%dev-with-data.quarkus.hibernate-orm.database.generation=update
%dev-with-data.quarkus.hibernate-orm.sql-load-script=

# TEST
%test.quarkus.hibernate-orm.database.generation=drop-and-create
%test.quarkus.hibernate-orm.sql-load-script=import-test.sql

# make sure not to modify the schame in prod mode: if needed, integrate FlyWay
%prod.quarkus.hibernate-orm.database.generation=none
%prod.quarkus.hibernate-orm.sql-load-script=no-file

quarkus.hibernate-orm.log.sql=false
quarkus.hibernate-orm.statistics=false

quarkus.http.port=8380
quarkus.http.ssl-port=8443
quarkus.http.root-path=/api/v1

quarkus.http.test-port=8381
quarkus.http.test-ssl-port=8444

# To get HTTPS working, either a key-store-file must be specified, or a certificate provided. See the following options:
# The file path to a server certificate or certificate chain in PEM format.
%prod.quarkus.http.ssl.certificate.file=/cert.pem
# The file path to the corresponding certificate private key file in PEM format.
%prod.quarkus.http.ssl.certificate.key-file=/key.pem
# An optional key store which holds the certificate information instead of specifying separate files.
#quarkus.http.ssl.certificate.key-store-file
# An optional parameter to specify type of the key store file. If not given, the type is automatically detected based on the file name.
#quarkus.http.ssl.certificate.key-store-file-type

quarkus.swagger-ui.always-include=true

# Kafka URL
kafka.bootstrap.servers=localhost:9092

# Configure the Kafka source (we read from it)
mp.messaging.incoming.InstitutionClientEvents.connector=smallrye-kafka
%prod.mp.messaging.incoming.InstitutionClientEvents.group.id=exchange-service-${group.id}
mp.messaging.incoming.InstitutionClientEvents.auto.offset.reset=earliest
mp.messaging.incoming.InstitutionClientEvents.enable.auto.commit=false
mp.messaging.incoming.InstitutionClientEvents.value.deserializer=io.confluent.kafka.serializers.KafkaAvroDeserializer
mp.messaging.incoming.InstitutionClientEvents.schema.registry.url=http://schema-registry:8081
%dev.mp.messaging.incoming.InstitutionClientEvents.schema.registry.url=http://localhost:8081
%dev-with-data.mp.messaging.incoming.InstitutionClientEvents.schema.registry.url=http://localhost:8081
mp.messaging.incoming.InstitutionClientEvents.specific.avro.reader=true

mp.messaging.incoming.VerfuegungEvents.connector=smallrye-kafka
%prod.mp.messaging.incoming.VerfuegungEvents.group.id=exchange-service-${group.id}
mp.messaging.incoming.VerfuegungEvents.auto.offset.reset=earliest
mp.messaging.incoming.VerfuegungEvents.enable.auto.commit=false
mp.messaging.incoming.VerfuegungEvents.value.deserializer=io.confluent.kafka.serializers.KafkaAvroDeserializer
mp.messaging.incoming.VerfuegungEvents.schema.registry.url=http://schema-registry:8081
%dev.mp.messaging.incoming.VerfuegungEvents.schema.registry.url=http://localhost:8081
%dev-with-data.mp.messaging.incoming.VerfuegungEvents.schema.registry.url=http://localhost:8081
mp.messaging.incoming.VerfuegungEvents.specific.avro.reader=true

mp.messaging.incoming.InstitutionEvents.connector=smallrye-kafka
%prod.mp.messaging.incoming.InstitutionEvents.group.id=exchange-service-${group.id}
mp.messaging.incoming.InstitutionEvents.auto.offset.reset=earliest
mp.messaging.incoming.InstitutionEvents.enable.auto.commit=false
mp.messaging.incoming.InstitutionEvents.value.deserializer=io.confluent.kafka.serializers.KafkaAvroDeserializer
mp.messaging.incoming.InstitutionEvents.schema.registry.url=http://schema-registry:8081
%dev.mp.messaging.incoming.InstitutionEvents.schema.registry.url=http://localhost:8081
%dev-with-data.mp.messaging.incoming.InstitutionEvents.schema.registry.url=http://localhost:8081
mp.messaging.incoming.InstitutionEvents.specific.avro.reader=true

mp.messaging.incoming.BetreuungAnfrageEvents.connector=smallrye-kafka
%prod.mp.messaging.incoming.BetreuungAnfrageEvents.group.id=exchange-service-${group.id}
mp.messaging.incoming.BetreuungAnfrageEvents.auto.offset.reset=earliest
mp.messaging.incoming.BetreuungAnfrageEvents.enable.auto.commit=false
mp.messaging.incoming.BetreuungAnfrageEvents.value.deserializer=io.confluent.kafka.serializers.KafkaAvroDeserializer
mp.messaging.incoming.BetreuungAnfrageEvents.schema.registry.url=http://schema-registry:8081
%dev.mp.messaging.incoming.BetreuungAnfrageEvents.schema.registry.url=http://localhost:8081
%dev-with-data.mp.messaging.incoming.BetreuungAnfrageEvents.schema.registry.url=http://localhost:8081
mp.messaging.incoming.BetreuungAnfrageEvents.specific.avro.reader=true

mp.messaging.outgoing.PlatzbestaetigungBetreuungEvents.connector=smallrye-kafka
%prod.mp.messaging.outgoing.PlatzbestaetigungBetreuungEvents.group.id=exchange-service-${group.id}
# make sure the message is on all Kafka brokers (can impact performance)
mp.messaging.outgoing.PlatzbestaetigungBetreuungEvents.acks=all
# wait, inorder to respond the REST request only after the ACK is received
mp.messaging.outgoing.PlatzbestaetigungBetreuungEvents.waitForWriteCompletion=true
# don't retry indefinitely. When communication to Kafka is currently broken, make the REST request fail immediately.
mp.messaging.outgoing.PlatzbestaetigungBetreuungEvents.retries=0
mp.messaging.outgoing.PlatzbestaetigungBetreuungEvents.delivery.timeout.ms=10000
mp.messaging.outgoing.PlatzbestaetigungBetreuungEvents.request.timeout.ms=10000
mp.messaging.outgoing.PlatzbestaetigungBetreuungEvents.value.serializer=io.confluent.kafka.serializers.KafkaAvroSerializer
mp.messaging.outgoing.PlatzbestaetigungBetreuungEvents.schema.registry.url=http://schema-registry:8081
%dev.mp.messaging.outgoing.PlatzbestaetigungBetreuungEvents.schema.registry.url=http://localhost:8081
%dev-with-data.mp.messaging.outgoing.PlatzbestaetigungBetreuungEvents.schema.registry.url=http://localhost:8081

quarkus.log.sentry.in-app-packages=ch.dvbern.kibon

#quarkus.log.level=DEBUG
%dev-with-data.quarkus.log.category."io.smallrye.reactive.messaging.kafka".level=DEBUG
%dev-with-data.quarkus.log.category."ch.dvbern.kibon.api.platzbestaetigung.PlatzbestaetigungResource".level=DEBUG

# Flyway configuration
quarkus.flyway.migrate-at-start=true
%test.quarkus.flyway.migrate-at-start=false
# when using hibernate drop-and-craete, the database is obviously not empty, thus activate baselien-on-migrate
%dev.quarkus.flyway.baseline-on-migrate=true
%dev.quarkus.flyway.baseline-version=0.0.0
%dev.quarkus.flyway.baseline-description=Initial version
